## Sprint 7

> Essa Sprint foi o maior ponto de entrada para o mundo de Big Data, eu pude conhecer alguns dos serviços mais famosos no mundo de dados e bastante requisitados em grandes empresas e utilizar novamente serviços no ambiente da AWS como o Glue, Lake formation, IAM e outros, e tambem pude dar inicio ao principal desafio do programa de bolsas, reforçando os conhecimentos em Python e Docker.

### Aprendizados

- Hadoop
- MapReduce
- Pyspark
- Big Data
- AWS Glue

## Desafio - Parte 1

Na pasta de [desafio](https://github.com/EdnaldoLuiz/AWS-Cloud-Data-Engineering-Compass-UOL/tree/main/sprint-7/desafio/parte-1) consta o código usado para a criação do bucket s3 e suas subpastas com os dados do CSV na AWS usando uma imagem Docker

## Certificados

Na pasta [certificados](https://github.com/EdnaldoLuiz/AWS-Cloud-Data-Engineering-Compass-UOL/tree/main/sprint-7/certificados) consta as imagens dos certificados da Sprint 7

## Meu Aprendizado

Na pasta [meu-aprendizado](https://github.com/EdnaldoLuiz/AWS-Cloud-Data-Engineering-Compass-UOL/tree/main/sprint-7/meu-aprendizado) estão os pontos chaves que pude absorver durante essa Sprint.

## Exercícios

### Python

Na pasta [python](https://github.com/EdnaldoLuiz/AWS-Cloud-Data-Engineering-Compass-UOL/tree/main/sprint-7/exercicios/python) consta todos os 4 arquivos dos exercícios python da Udemy

## Pyspark

Na pasta [pyspark](https://github.com/EdnaldoLuiz/AWS-Cloud-Data-Engineering-Compass-UOL/tree/main/sprint-7/exercicios/pyspark) consta o arquivo com os dados que usei para a criação do script, a imagem Docker e os prints dos passos realizados

## Lab Glue

Na pasta [lab-AWS](https://github.com/EdnaldoLuiz/AWS-Cloud-Data-Engineering-Compass-UOL/tree/main/sprint-7/exercicios/lab-AWS) consta os prints dos passos realizados no console da AWS, desde a criação dos recursos até os resultados obtidos no bucket s3 e os logs gerados no Cloud Watch

